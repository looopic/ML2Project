{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LTJLfeyavaXGWEsUgOUEEcu2vi8QZDyR",
      "authorship_tag": "ABX9TyO4TrOxInCO2KoeLecNdhmB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/looopic/ML2Project/blob/main/ML2Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visual text recognition model by Carlo Huser (husercar@students.zhaw.ch)\n",
        "\n",
        "\n",
        "This model is used to extract the ingredients from an image of groceries. I want to use this model to build an app to detect allergies or intolerances on specific ingredients."
      ],
      "metadata": {
        "id": "SycYOONrmClP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "I was thinking of making my own dataset for this problem, but I quickly found out, that it's too time consuming to annotate every single picture on my own.\n",
        "Therefore I searched the internet for a dataset I could use and found the TextOCR dataset on kaggle (https://www.kaggle.com/datasets/robikscube/textocr-text-extraction-from-images-dataset?select=annot.csv)"
      ],
      "metadata": {
        "id": "Y6xGoGSZnEXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import of the dataset\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dXhby2cmyF1K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = pd.read_parquet('/content/annot.parquet')\n",
        "images = pd.read_parquet('/content/img.parquet')\n",
        "frames = glob('/content/train_val_images/train_images/*')\n",
        "\n",
        "display(images)"
      ],
      "metadata": {
        "id": "fx1WdWPkt71C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "ax.imshow(plt.imread(frames[0]))\n",
        "ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zusp7sYW37j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_id = frames[0].split('/')[-1].split('.')[0]\n",
        "annotations.query('image_id == @image_id')"
      ],
      "metadata": {
        "id": "hIYuXBNJ4ixb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "I'm following the tutorial on medium.com (https://medium.com/geekculture/building-a-complete-ocr-engine-from-scratch-in-python-be1fd184753b)"
      ],
      "metadata": {
        "id": "HDutK2Jhm_BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "import os\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "mlA2ZiTCAZhJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_list=os.listdir('/content/train_val_images/train_images/')\n",
        "image_list=[filename.split(\".\")[0]for filename in image_list]"
      ],
      "metadata": {
        "id": "_FF9xToxAgXI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(img,seg_img):\n",
        "  plt.figure(figsize=(20,20))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(img)\n",
        "  plt.title('Image')\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(seg_img,cmap='gray')\n",
        "  plt.title('Segmented Image')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2eIHzJ4cAxzA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roundup(x):\n",
        "    return int(math.ceil(x / 10.0)) * 10"
      ],
      "metadata": {
        "id": "VplvurGAA7_g"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_segmented_img(img,n_classes):\n",
        "    \"\"\"\n",
        "    Loads in the segmented image and create suitable segmentation label.\n",
        "    \"\"\"\n",
        "    seg_labels=np.zeros((512,512,1))\n",
        "    img=cv2.resize(img,(512,512))\n",
        "    img=img[:,:,0]\n",
        "    cl_list=[0,24]\n",
        "\n",
        "    \n",
        "    seg_labels[:,:,0]=(img!=0).astype(int)\n",
        "\n",
        "\n",
        "    return seg_labels"
      ],
      "metadata": {
        "id": "xXvVO6EVA9tQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_img(img):\n",
        "\told_h,old_w=img.shape[0],img.shape[1]\n",
        "\n",
        "\t#Pad the height.\n",
        "\n",
        "\t#If height is less than 512 then pad to 512\n",
        "\tif old_h<512:\n",
        "\t\tto_pad=np.ones((512-old_h,old_w))*255\n",
        "\t\timg=np.concatenate((img,to_pad))\n",
        "\t\tnew_height=512\n",
        "\telse:\n",
        "\t#If height >512 then pad to nearest 10.\n",
        "\t\tto_pad=np.ones((roundup(old_h)-old_h,old_w))*255\n",
        "\t\timg=np.concatenate((img,to_pad))\n",
        "\t\tnew_height=roundup(old_h)\n",
        "\n",
        "\t#Pad the width.\n",
        "\tif old_w<512:\n",
        "\t\tto_pad=np.ones((new_height,512-old_w))*255\n",
        "\t\timg=np.concatenate((img,to_pad),axis=1)\n",
        "\t\tnew_width=512\n",
        "\telse:\n",
        "\t\tto_pad=np.ones((new_height,roundup(old_w)-old_w))*255\n",
        "\t\timg=np.concatenate((img,to_pad),axis=1)\n",
        "\t\tnew_width=roundup(old_w)-old_w\n",
        "\treturn img\n"
      ],
      "metadata": {
        "id": "kZeimr-JA_qx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_seg(img):\n",
        "\told_h,old_w=img.shape[0],img.shape[1]\n",
        "\n",
        "\t#Pad the height.\n",
        "\n",
        "\t#If height is less than 512 then pad to 512\n",
        "\tif old_h<512:\n",
        "\t\tto_pad=np.zeros((512-old_h,old_w))\n",
        "\t\timg=np.concatenate((img,to_pad))\n",
        "\t\tnew_height=512\n",
        "\telse:\n",
        "\t#If height >512 then pad to nearest 10.\n",
        "\t\tto_pad=np.zeros((roundup(old_h)-old_h,old_w))\n",
        "\t\timg=np.concatenate((img,to_pad))\n",
        "\t\tnew_height=roundup(old_h)\n",
        "\n",
        "\t#Pad the width.\n",
        "\tif old_w<512:\n",
        "\t\tto_pad=np.zeros((new_height,512-old_w))\n",
        "\t\timg=np.concatenate((img,to_pad),axis=1)\n",
        "\t\tnew_width=512\n",
        "\telse:\n",
        "\t\tto_pad=np.zeros((new_height,roundup(old_w)-old_w))\n",
        "\t\timg=np.concatenate((img,to_pad),axis=1)\n",
        "\t\tnew_width=roundup(old_w)-old_w\n",
        "\treturn img\n"
      ],
      "metadata": {
        "id": "id4XizNcBHnw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_generator(filelist,n_classes,batch_size):\n",
        "  while True:\n",
        "    X=[]\n",
        "    Y=[]\n",
        "    for i in range(batch_size):\n",
        "      fn=random.choice(filelist)\n",
        "      img=cv2.imread(f'/content/train_val_images/train_images/{fn}.jpg',0)\n",
        "      img=pad_img(img)\n",
        "      ret,img=cv2.threshold(img,150,255,cv2.THRESH_BINARY_INV)\n",
        "      \n",
        "\n",
        "      img=cv2.resize(img,(512,512))\n",
        "      img=np.expand_dims(img,axis=-1)\n",
        "      #img = np.stack((img,)*3, axis=-1)\n",
        "      img=img/255\n",
        "\n",
        "      seg=cv2.imread(f'/content/Dataset1/mask/{fn}_mask.png',0)\n",
        "      seg=pad_seg(seg)\n",
        "      seg=cv2.resize(seg,(512,512))\n",
        "      seg = np.stack((seg,)*3, axis=-1)\n",
        "      seg=get_segmented_img(seg,n_classes)\n",
        "\n",
        "      X.append(img)\n",
        "      Y.append(seg)\n",
        "    yield np.array(X),np.array(Y)\n"
      ],
      "metadata": {
        "id": "5eFzjTZ0BLCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(image_list)\n",
        "file_train=image_list[0:int(0.75*len(image_list))]\n",
        "file_test=image_list[int(0.75*len(image_list)):]"
      ],
      "metadata": {
        "id": "q1fBkMPgBlcR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet(pretrained_weights = None,input_size = (512,512,1)):\n",
        "  inputs = Input(input_size)\n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "  drop4 = Dropout(0.5)(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "  drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "  merge6 = concatenate([drop4,up6], axis = 3)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "  merge7 = concatenate([conv3,up7], axis = 3)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "  merge8 = concatenate([conv2,up8], axis = 3)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "  merge9 = concatenate([conv1,up9], axis = 3)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "  conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "  model = Model(inputs,conv10)\n",
        "\n",
        "  model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  \n",
        "  #model.summary()\n",
        "\n",
        "  if(pretrained_weights):\n",
        "    model.load_weights(pretrained_weights)\n",
        "\n",
        "  return model\n",
        "\n",
        "model=unet()\n",
        "\n",
        "\n",
        "mc = ModelCheckpoint('weights{epoch:08d}.h5', \n",
        "                                     save_weights_only=True, save_freq=1)"
      ],
      "metadata": {
        "id": "xsBNRmIoCP3Z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(batch_generator(file_train,2,2),epochs=5,steps_per_epoch=1000,validation_data=batch_generator(file_test,2,2),\n",
        "                    validation_steps=400,callbacks=[mc],shuffle=1)"
      ],
      "metadata": {
        "id": "kjOIpv4uCyNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation and Comparision"
      ],
      "metadata": {
        "id": "wtwoGk-qyOJE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJTO4xRsyW-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}